"""
tools : Outils pour le traitement des donn√©es

Objectif :
-----------
Le module vise √† fournir un ensemble d'outils pour faciliter le traitement des donn√©es,
depuis l'acquisition par le biais du web crawling jusqu'√† la manipulation et la mise en forme
des dataframes.
"""

from bs4 import BeautifulSoup
import requests  
import pandas as pd 
from tqdm import tqdm

class Crawler :

    """ [Class Docstring]
    Crawler: Classe d'extraction et d'analyse de contenu HTML.

    Cette classe est con√ßue pour extraire le contenu HTML d'une URL sp√©cifi√©e et fournir 
    des m√©thodes pour explorer et extraire des informations sp√©cifiques du contenu.

    Attributs:
    ----------
    Aucun

    M√©thodes:
    ---------
    - extract_html(url: str) -> Union[BeautifulSoup, Dict[str, str]]:
        Effectue une requ√™te HTTP GET √† l'URL sp√©cifi√©e et renvoie le contenu HTML ou un 
        message d'erreur.
    
    - find_elements(html_content: BeautifulSoup, tag: str, class_name: Optional[str], 
                    element_id: Optional[str]) -> Tuple[str, Union[List[BeautifulSoup], None]]:
        Recherche tous les √©l√©ments HTML correspondants dans le contenu fourni en fonction 
        du tag, du nom de classe ou de l'ID et renvoie un tuple contenant un message et la 
        liste des √©l√©ments correspondants.

    - find_element(html_content: BeautifulSoup, tag: str, class_name: Optional[str], 
                   element_id: Optional[str]) -> Union[BeautifulSoup, Dict[str, str]]:
        Recherche le premier √©l√©ment HTML correspondant dans le contenu fourni et renvoie 
        l'√©l√©ment ou un message d'erreur.

    - extract_table(html_content: BeautifulSoup, class_name: Optional[str], table_id: Optional[str]) -> pd.DataFrame:
        Extrait une table du contenu HTML fourni, la convertit en un DataFrame pandas et 
        renvoie le DataFrame.

    Exemple d'utilisation:
    ----------------------
    crawler = Crawler()
    html_content = crawler.extract_html("https://www.example.com")
    message, elements = crawler.find_elements(html_content, 'table', class_name='myTable')
    """

    @staticmethod
    def extract_html(url: str):

        """ [Function Docstring]
        Extrait le contenu HTML d'une URL donn√©e.

        Param√®tres:
        -----------
        url : str
            L'URL √† partir de laquelle extraire le contenu HTML.

        Retourne:
        --------
        BeautifulSoup
            Une instance de BeautifulSoup contenant le contenu HTML si la requ√™te est r√©ussie.
        Dict[str, str]
            Un dictionnaire avec un message d'erreur si la requ√™te √©choue ou si un autre probl√®me survient.

        Exemples:
        --------
        >>> extract_html("https://www.example.com")
        <html>...</html>

        >>> extract_html("https://www.invalid-url.com")
        {'error': 'An error occurred: ...'}
        """

        try:
            response = requests.get(url)

            # Si la requ√™te est r√©ussie (code 200), on renvoie le contenu HTML
            if response.status_code == 200:
                return BeautifulSoup(response.text, 'html.parser')

            # Sinon, on renvoie un dictionnaire d'erreur
            return print({"error": f"error in get method: {response.status_code}"})
        
        # Gestion des exceptions li√©es aux requ√™tes
        except requests.RequestException as e:
            return {"error": f"An error occurred: {str(e)}"}
            
    @staticmethod
    def find_elements(html_content, tag, class_name=None, element_id=None):

        """ [Function Docstring]
        Recherche tous les √©l√©ments HTML dans le contenu HTML fourni en utilisant le tag et le nom de la classe ou l'ID.

        Param√®tres:
        -----------
        html_content : BeautifulSoup
            Objet BeautifulSoup contenant le contenu HTML √† analyser.
        tag : str
            Tag HTML de l'√©l√©ment √† rechercher (par exemple, 'table', 'div', 'a', etc.).
        class_name : str, optional
            Nom de la classe CSS de l'√©l√©ment √† rechercher. Utilis√© pour la s√©lection d'√©l√©ment bas√©e sur la classe.
        element_id : str, optional
            ID de l'√©l√©ment √† rechercher. Utilis√© pour la s√©lection d'√©l√©ment bas√©e sur l'ID.

        Retourne:
        --------
        tuple (str, list of BeautifulSoup objects or None)
            Renvoie une paire (message, liste des √©l√©ments trouv√©s). Le message fournit le nombre de correspondances trouv√©es. Si aucun √©l√©ment n'est trouv√©, le message indique une absence de correspondance.

        Exemples:
        --------
        >>> from bs4 import BeautifulSoup
        >>> html = "<html><body><table class='myTable'><tr><td>Content</td></tr></table></body></html>"
        >>> soup = BeautifulSoup(html, 'html.parser')
        >>> message, elements = find_elements(soup, 'table', class_name='myTable')
        >>> print(message)
        1 correspondance(s) trouv√©e(s) avec le tag table et myTable

        Exceptions:
        ----------
        ValueError: Si l'objet html_content fourni n'est pas une instance de BeautifulSoup, ou si ni class_name ni element_id ne sont fournis.
        """

        # V√©rification du type de l'objet html_content
        if not isinstance(html_content, BeautifulSoup): 
            raise ValueError("L'entr√©e doit √™tre un objet BeautifulSoup.")
        
        # Recherche d'√©l√©ment en utilisant le nom de la classe ou l'ID
        if class_name is not None: 
            res = html_content.find_all(tag, {'class': class_name})
        elif element_id is not None: 
            res = html_content.find_all(tag, id=element_id)
        else:
            raise ValueError("L'un des deux param√®tres class_name ou element_id doit √™tre fourni.")
        
        # V√©rification du nombre d'√©l√©ments trouv√©s
        if res is None:
            return f"aucune correspondance avec le tag {tag} et {class_name or element_id}", None
        else:
            return f"{(len(res))} correspondance(s) trouv√©e(s) avec le tag {tag} et {class_name or element_id}", res

        
    @staticmethod
    def find_element(html_content, tag, class_name=None, element_id=None, attrs_key = None, attrs_value = None): 

        """ [Function Docstring]
        Recherche le premier √©l√©ment HTML correspondant dans le contenu HTML fourni en utilisant le tag et le nom de la classe ou l'ID.

        Param√®tres:
        -----------
        html_content : BeautifulSoup
            Objet BeautifulSoup contenant le contenu HTML √† analyser.
        tag : str
            Tag HTML de l'√©l√©ment √† rechercher (par exemple, 'table', 'div', 'a', etc.).
        class_name : str, optional
            Nom de la classe CSS de l'√©l√©ment √† rechercher. Utilis√© pour la s√©lection d'√©l√©ment bas√©e sur la classe.
        element_id : str, optional
            ID de l'√©l√©ment √† rechercher. Utilis√© pour la s√©lection d'√©l√©ment bas√©e sur l'ID.

        Retourne:
        --------
        BeautifulSoup object or dict
            Retourne le premier √©l√©ment BeautifulSoup trouv√©. Si aucun √©l√©ment n'est trouv√©, retourne un dictionnaire avec un message d'erreur.

        Exemples:
        --------
        >>> from bs4 import BeautifulSoup
        >>> html = "<html><body><div class='myDiv'>Content</div></body></html>"
        >>> soup = BeautifulSoup(html, 'html.parser')
        >>> element = find_element(soup, 'div', class_name='myDiv')
        >>> print(element)
        <div class="myDiv">Content</div>

        Exceptions:
        ----------
        ValueError: Si l'objet html_content fourni n'est pas une instance de BeautifulSoup, ou si ni class_name ni element_id ne sont fournis.
        """
        
        # V√©rification du type de l'objet html_content
        if not isinstance(html_content, BeautifulSoup): 
            raise ValueError("L'entr√©e doit √™tre un objet BeautifulSoup.")
        
        # Recherche d'√©l√©ment en utilisant le nom de la classe ou l'ID
        # Si class_name est fourni, recherche par classe
        if class_name is not None: 
            res = html_content.find(tag, {'class': class_name})
        # Si element_id est fourni, recherche par ID
        elif element_id is not None: 
            res = html_content.find(tag, id=element_id)
        # Si aucun n'est fourni, l√®ve une exception
        elif attrs_key and attrs_value is not None : 
            res = html_content.find(tag, attrs= {attrs_key : attrs_value})
        else:
            raise ValueError("L'un des deux param√®tres class_name ou element_id doit √™tre fourni.")
        
        # Si aucun √©l√©ment n'est trouv√©, retourne un dictionnaire contenant un message d'erreur
        if res is None :
            return {f"aucune correspondance avec le tag {tag} et {class_name or element_id}"}  
        # Si un √©l√©ment est trouv√©, imprime un message et retourne l'√©l√©ment trouv√©
        else:
            return res

    @staticmethod  
    def extract_table(html_content, class_name=None, table_id=None):

        """ [Function Docstring]
        Extrait une table du contenu HTML fourni en utilisant soit le nom de la classe `class_name` soit l'ID `table_id`.

        Param√®tres:
        -----------
        html_content : BeautifulSoup
            Objet BeautifulSoup contenant le contenu HTML √† analyser.
        class_name : str, optional
            Nom de la classe CSS de la table √† extraire. Utilis√© pour la s√©lection de la table bas√©e sur la classe.
        table_id : str, optional
            ID de la table √† extraire. Utilis√© pour la s√©lection de la table bas√©e sur l'ID.

        Retourne:
        --------
        pd.DataFrame
            DataFrame contenant les donn√©es de la table extraites.

        Exceptions:
        ----------
        ValueError: Si l'objet `html_content` fourni n'est pas une instance de BeautifulSoup, si la table n'est pas trouv√©e, ou si ni `class_name` ni `table_id` ne sont fournis.

        Exemples:
        --------
        >>> from bs4 import BeautifulSoup
        >>> html = "<html><body><table class='myTable'><tr><th>Header</th></tr><tr><td>Data</td></tr></table></body></html>"
        >>> soup = BeautifulSoup(html, 'html.parser')
        >>> df = extract_table(soup, class_name='myTable')
        >>> print(df)
        Header
        0   Data
        """

        if not isinstance(html_content, BeautifulSoup): 
            raise ValueError("L'entr√©e doit √™tre un objet BeautifulSoup.")
        
        # Extrait la table en utilisant le nom de classe ou l'id
        if class_name is not None: 
            table = html_content.find('table', class_ = class_name)
        elif table_id is not None: 
            table = html_content.find('table', id=table_id)
        else:
            raise ValueError("L'un des deux param√®tres class_name ou table_id doit √™tre fourni.")
        
        # S'assure que la table est trouv√©e
        if table is None:
            raise ValueError("Table non trouv√©e.")
        
        # Extrait l'en-t√™te
        header = [th.text.strip() for th in table.find_all('th')]
            
        # Extrait les donn√©es des lignes
        rows_data = []
        for row in table.find_all('tr')[1:]:  # Exclut la ligne d'en-t√™te
            rows_data.append([td.text.strip() for td in row.find_all('td')])
                
        # Convertit en DataFrame
        df = pd.DataFrame(rows_data, columns=header)
        return df

class clean_df : 

    @staticmethod
    def convert_str_na_to_nan(df, na_values):
        """
        Convertit les cha√Ænes de caract√®res repr√©sentant des NA en NaN.

        Param√®tres:
        - df (pd.DataFrame): Le DataFrame en entr√©e.
        - na_values (list of str): Liste des cha√Ænes de caract√®res repr√©sentant des NA.

        Retourne:
        pd.DataFrame: DataFrame avec les cha√Ænes repr√©sentant des NA converties en NaN.

        Exemple d'utilisation:
        convert_str_na_to_nan(df, na_values=["NA", "N/A", "null"])
        """
        return df.replace(na_values, pd.NA)

    @staticmethod
    def drop_na(df, col=None, cols=None):

        if not isinstance(df, pd.DataFrame):
            raise ValueError("L'entr√©e doit √™tre un DataFrame Pandas.")

        # V√©rifie si le param√®tre `col` est utilis√©.
        if col is not None:
            if col not in df.columns:
                raise ValueError(f"Colonne {col} non trouv√©e dans le DataFrame.")
            return df.dropna(subset=[col])

        # V√©rifie si le param√®tre `cols` est utilis√©.
        elif cols is not None:
            # V√©rifie que cols est une liste
            if not isinstance(cols, list):
                raise ValueError("L'argument `cols` doit √™tre une liste de noms de colonnes.")

            # V√©rifie que chaque √©l√©ment de cols est une cha√Æne et qu'il existe dans le DataFrame
            for col_name in cols:
                if not isinstance(col_name, str):
                    raise ValueError("Tous les √©l√©ments de `cols` doivent √™tre des cha√Ænes repr√©sentant les noms de colonnes.")
                if col_name not in df.columns:
                    raise ValueError(f"Colonne {col_name} non trouv√©e dans le DataFrame.")
            
            return df.dropna(subset=cols)
        
        # Si ni `col` ni `cols` n'est sp√©cifi√©, supprime les lignes avec NA dans toutes les colonnes.
        else:
            return df.dropna()
        
class Merge :

    def missing_table (url): 

        res = Crawler.extract_html(url)
        table = Crawler.find_element(res, tag='table', element_id='test-suite-results')

        missing_table = {}
        for row in table.findAll('tr'):
            header = row.find('th').text
            missing_table[header] = "NA"
        
        return missing_table
    
    def fetch_data(url, missing_table, session):
        try :
            res = Crawler.extract_html(url)
            table = Crawler.find_element(res, tag='table', element_id='test-suite-results')
            data = {}
            for row in table.findAll('tr'):
                header = row.find('th').text
                value = row.find('td').text
                data[header] = value
            return data 
        except: 
            data = missing_table
            return data 
        
def tqdm_executor_map(executor, function, *args, **kwargs):
    """
    Une fonction pour ex√©cuter une fonction de mani√®re parall√®le tout en affichant une barre de progression avec tqdm.

    Arguments:
    - executor : Un ex√©cuteur de type concurrent.futures (ThreadPoolExecutor ou ProcessPoolExecutor).
    - function : La fonction √† ex√©cuter en parall√®le.
    - *args : Les arguments √† passer √† la fonction.
    - **kwargs : Les arguments cl√©/valeur √† passer √† la fonction.

    Retourne :
    - Une liste des r√©sultats renvoy√©s par la fonction.
    """

    # D√©finition des codes de couleur pour la barre de progression.
    DARK_GREEN = "\033[32m"
    RED = "\033[91m"
    BLUE = "\033[94m"
    ENDC = "\033[0m"
    
    # Format personnalis√© pour tqdm en utlisant les codes couleurs 
    bar_format = "{l_bar}" + DARK_GREEN + "‚ñà{bar:25}‚ñë" + ENDC + " " + RED + "{n_fmt}/{total_fmt}" + ENDC + " " + BLUE + "[{rate_fmt} eta {remaining}]" + ENDC

    # Utilise l'ex√©cuteur pour ex√©cuter la fonction en parall√®le.
    gen = executor.map(function, *args)
    
    # Si un total est fourni dans kwargs, il est utilis√©. Sinon, il est laiss√© √† None.
    total = kwargs.get('total', None)
    
    # Enveloppe le g√©n√©rateur avec tqdm pour afficher la barre de progression.
    return list(tqdm(gen, 
                    desc="Processing data üöÄ ", 
                    bar_format=bar_format,
                    dynamic_ncols=True, 
                    mininterval=0.25,
                    total=total))
